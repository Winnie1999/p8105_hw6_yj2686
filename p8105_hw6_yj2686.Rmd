---
title: "p8105_hw6_yj2686"
author: "Yiqun Jin"
date: "11/30/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1

### Load and clean the data for regression analysis

```{r birthweight}
birthweight = read.csv("./birthweight.csv") %>% 
  mutate(babysex = factor(if_else(babysex == 1, "male", "female")),
         frace = factor(recode(frace, '1' = "White", '2' = "Black", '3' = "Asian", 
                               '4' = "Puerto Rican", '8' = "Other", '9' = "Unknown")),
         mrace = factor(recode(mrace,'1' = "White", '2' = "Black", '3' = "Asian", 
                               '4' = "Puerto Rican", '8' = "Other", '9' = "Unknown")),
         malform = factor(recode(malform, '0' = "absent", '1' = "present")))
# check for missing data
sum(is.na(birthweight))
```

### Propose a regression model for birth weight

Since birth weight of baby is usually associated with baby's length at birth, I made a scatter plot of baby's length at birth `blength`. 

```{r}
birthweight %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  labs(title = "Scatter plot of baby's birth weight and baby's birth length") +
  theme(plot.title = element_text(hjust = 0.5))
```

According to the scatter plot, it seemed that there might be a linear relationship between baby's length at birth `blength` and birth weight `bwt`. Thus, I will try `blength` as the predictor of the regression model for birth weight and make a plot of model residuals against fitted values

```{r}
fit1 = lm(bwt ~ blength, data = birthweight)
fit1 %>% 
  broom::tidy() %>% 
  knitr::kable()

birthweight %>% 
  modelr::add_residuals(fit1) %>% 
  modelr::add_predictions(fit1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Plot of model residuals against fitted values for fit1 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

### Compare your model to two others

fit2: Using length at birth and gestational age as predictors (main effects only)
fit3: Using head circumference, length, sex, and all interactions (including the three-way interaction) between these as predictors

```{r}
fit2 = lm(bwt ~ blength + gaweeks,birthweight)

fit2 %>% 
  broom::tidy() %>% 
  knitr::kable()

birthweight %>% 
  modelr::add_residuals(fit2) %>% 
  modelr::add_predictions(fit2) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Plot of model residuals against fitted values for fit2 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))

fit3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, birthweight)

fit3 %>% 
  broom::tidy() %>% 
  knitr::kable()

birthweight %>% 
  modelr::add_residuals(fit3) %>% 
  modelr::add_predictions(fit3) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Plot of model residuals against fitted values for fit3 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

### Make this comparison in terms of the cross-validated prediction error

```{r}
cv_df = 
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    fit1_mod = map(train, ~lm(bwt ~ blength, data = birthweight)),
    fit2_mod = map(train, ~lm(bwt ~ blength + gaweeks,birthweight)),
    fit3_mod = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex +       blength*babysex + bhead*blength*babysex, birthweight))
  ) %>% 
  mutate(
    rmse_fit1 = map2_dbl(fit1_mod, test, ~rmse(model = .x, data = .y)),
    rmse_fit2 = map2_dbl(fit2_mod, test, ~rmse(model = .x, data = .y)),
    rmse_fit3 = map2_dbl(fit3_mod, test, ~rmse(model = .x, data = .y))
  )
  
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "distribution of RMSE values for three candidate model",
    y = "Root-mean-square-deviation"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

According to the distribution of RMSE, fit3 model have the lowest RMSE value and the distribution is more centered, meaning that fit3 would be the most optimal model among three candidate models


## Problem 2

### Load 2017 Central Park weather data

```{r weather data}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### Bootstrapping and plot the distribution of estimates

```{r}
bootstrap = 
  weather_df %>% 
  modelr::bootstrap(n = 5000, id = "strap_number") %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results1 = map(models, broom::glance),
    results2 = map(models, broom::tidy)
  ) 
```

#### For $\hat{r}^2$

```{r}
r_squared = bootstrap %>% 
  unnest(results1) %>% 
  select(r.squared)
  
r_squared %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    title = "Distribution of r-squared"
  ) +
  theme(plot.title = element_text(hjust = 0.5))

ci_r_squared = r_squared %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  ) 

ci_r_squared %>% 
  knitr::kable()
```

* Description for $\hat{r}^2$: 

The distribution plot of $\hat{r}^2$ is approximately normal, unimodal, slightly left-skewed and centered around 0.912.
The 95% Confidence Interval for $\hat{r}^2$ is (`r ci_r_squared[1]`, `r ci_r_squared[2]`)

#### For $\log(\hat{\beta}_0 * \hat{\beta}_1)$ 

```{r}
logbeta = bootstrap %>% 
  unnest(results2) %>% 
  select(strap_number, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    log_beta = log(intercept * tmin)
  )

logbeta %>% 
  ggplot(aes(log_beta)) +
  geom_density() +
  labs(
    title = "Distribution of log(beta0 * beta1)"
  ) +
  theme(plot.title = element_text(hjust = 0.5))

ci_logbeta = logbeta %>% 
  summarize(
    ci_lower = quantile(log_beta, 0.025),
    ci_upper = quantile(log_beta, 0.975)
  ) 

ci_logbeta %>% 
  knitr::kable()

```

* Description for $\log(\hat{\beta}_0 * \hat{\beta}_1)$ : 

The distribution plot of $\log(\hat{\beta}_0 * \hat{\beta}_1)$ is approximately normal, unimodal, and centered around 2.01.
The 95% Confidence Interval for $\log(\hat{\beta}_0 * \hat{\beta}_1)$ is (`r ci_logbeta[1]`, `r ci_logbeta[2]`)